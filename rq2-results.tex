\subsection{Try-Catch Statement Detection Effectiveness (RQ2)}
\label{sec:rq2}

\begin{table}[t]
  \caption{Try-Catch Statement Detection Effectiveness (RQ2)}
  \vspace{-12pt}
	\begin{center}
		\small
		\renewcommand{\arraystretch}{1} 
		\begin{tabular}{p{0.8cm}<{\centering}|p{0.4cm}<{\centering}|p{0.4cm}<{\centering}|p{0.4cm}<{\centering}|p{0.4cm}<{\centering}|p{0.4cm}<{\centering}|p{0.4cm}<{\centering}|p{0.4cm}<{\centering}|p{0.4cm}<{\centering}|p{0.4cm}<{\centering}|p{0.4cm}<{\centering}}
			\hline
			 	&  \multicolumn{10}{c}{Accuracy} \\
			\cline{2-11}
			     	&  N1  & N2   &  N3  & N4   &N5    & N6   &N7    & N8   &N9    & N10 \\
			\hline
			\tool       &  &  &  &  &  & 0.76 &  &  &  &   \\
			\hline
		\end{tabular}
		Nx is number of nodes in the explanation
                sub-graph (\code{try-catch} block)
		\label{tab:rq2}
	\end{center}
\end{table}

Table~\ref{tab:rq2} displays the result on detecting the statements
that need to be placed in a \code{try-catch} block. $N_x$ is a parameter
in GNNExplainer that defines the number of nodes in the explanation
graph $\mathcal{G}_C$, i.e., the number of statements to be placed in the
\code{try-catch} block.
%
As the number of nodes (statements) in $\mathcal{G}_C$ increases, the
number of correct statements covered also increases, thus, accuracy
increases. However, as the number of statements increases higher than
5, accuracy increases more slowly. In our dataset, the average size of
a \code{try-catch} block is 5.7 statements. As seen, the accuracy as
$N_x$=6 is 76\%. That is, by pointing out 6 statements on average,
{\tool} can correctly suggest 76\% of the total number of statements
in the dataset that need to be placed in \code{try-catch}
blocks. That is, it points out correctly 4.5 out of 6 statements to be
in a \code{try-catch} block. For the statements that do not need to be
placed in a \code{try-catch} block, {\tool} predicts correctly with
{\bf 81\%} accuracy (not shown).

\input{example-experiment}

\vspace{2pt}
\noindent {\bf Example.} Figure~\ref{fig:example-experiment} displays
an example that {\tool} made correct suggestions. {\bf First}, it made
a correct suggestion on the need of a \code{try-catch} block for the
code at lines 1--8, 16.  {\bf Second}, GNNExplainer pointed out that
{\xblock} used all the statements at lines 3--8 for such correct
prediction. As a consequence, {\tool} correctly suggests to place
lines 3--8 into a \code{try-catch} block. Note that, it also correctly
pointed out that lines 1 and 16 do not need to be inside the
\code{try-catch} block.  {\bf Third}, GNNExplainer gives three
statements at lines 3, 6, and 8 highest scores. We can see that those
lines contain three crucial API method calls: 1)
\code{FileInputStream}, 2) \code{read}, and 3) \code{close}. {\bf
  Fourth}, those three lines have data and control dependencies, which
could help the model learn the identities of the API elements via
their names \code{FileInputStream}, \code{read}, and \code{close},
despite that the code snippet does not have the fully-qualified names
for those elements. This confirms the need of integrating {\em program
  dependencies} in our solution. {\bf Finally}, {\tool} was also able
to learn from the training corpus that those names refer to those API
elements, which often correspond with the exception types: 1)
\code{FileInputStream} with \code{FileNotFoundException}, and 2)
\code{FileInputStream.read} and \code{FileInputStream.close} with
\code{IOException}.


%Note that {\tool} via {\xstate} predicts the statements to be placed
%in the \code{try-catch} block only after {\xblock} predicted that the
%given code needs such a block. Therefore, the incorrect cases from
%{\xblock} (i.e., those cases that need to be in a \code{try-catch}
%block but were predicted not) are also counted as incorrect in
%{\xstate}.

%{\color{red}{N1-N10 are the number of nodes that the subgraph contains which means the size of the try-catch block. Because the average size of the try-catch is 5.7, I currently pick 6 as the size of the try-catch block. The accuracy here is defined as: if a statement is in the try-catch block and our model put it in the subgraph, I regard it is correct $S_c$. All other conditions, I think they are incorrect. If there are $S$ statements in the try-catch block, the total accuracy is calculated as $S_c/S$. Later, I will add an example showing that the statement that our model predicted in the try-catch block contains the method call which lead to the correct exception types prediction.}}
