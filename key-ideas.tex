\subsection{Key Ideas}
\label{key:sec}

We introduce {\tool} with three functionalities for exception handling
recommendation: given a Java code snippet, it will

1) predict if a \code{try-catch} block is required ({\xblock}),

2) point out which statements in the code snippet need to be placed in
a \code{try-catch} block ({\xstate}), and

3) suggest the exception types to be in the \code{catch}
clause ({\xtype}).

From Observations, we design {\tool} with the following
ideas:

\subsubsection{{\bf [Key Idea 1] Neural Network-based approach to Exception Handling Recommendation by Learning from Complete Code}}
Instead of deterministically deriving the exceptions to be handled for
a given (incomplete) code snippet, following Observation~\ref{ob2}, we
follow a learning-based approach to learn to properly handle the
exceptions in the three above tasks.
%to learn to analyze that snippet to recommend if a \code{try-catch}
%block is needed and the statements to be placed within the
%\code{try-catch} block, and to recommend the exception types in the
%\code{catch} clause.
By learning from the \code{try-catch} blocks of the complete code in
the open-source projects in the training process, our model can
help the adaptation tasks.

%: 1) deciding what
%statements in the given code snippet to be placed in a
%\code{try-catch} block, and 2) deciding what exceptions to be handled.



\vspace{2pt}
\subsubsection{{\bf [Key Idea 2] Leveraging Language Model to learn Context to avoid
name ambiguity and Learning the Relations between API elements and
Exception types}} Instead of learning only the associations between an
API element and exception types as in IR-based approaches,
%XRank~\cite{xrank-fse20},
we leverage as the context the complete code in the training corpus,
which are parsable and provide the identities (i.e., FQNs) of the API
elements. In predicting for a code snippet, {\tool} will also leverage
the context and dependencies among the API elements to learn their
identities implicitly (see Observation~\ref{ob4}). Importantly, that
leads to the learning of the relations between the key API elements in
the context and the handled exception types (Observation~\ref{ob3}).

%\subsubsection{{\bf [Key Idea 3] Dual-Task Learning between {\xstate} and {\xtype}}} The learning of deciding what statements to be in a \code{try-catch}
%block could benefit much on the learning of deciding what exception
%types to be handled. In Figure~\ref{fig:example4}, if a model learns
%that line 3 (with \code{new\-Buffered\-Reader}) and line 5 (with
%\code{read\-Line}) need to be in \code{try-catch}, it could learn from
%the code corpus and decide \code{IOException} as the exception type to
%be handled. In contrast, if a model learns correctly that the
%\code{IOException} needs to be handled, from the history, it can learn
%that \code{new\-Buffered\-Reader} and \code{read\-Line} can throw that
%exception and determine that the line 3 and 5 need to be in
%\code{try-catch}.

%{\em
%\subsubsection{{\bf [Key Idea 3] Span-based ...}}
%We seek inspiration from the neural network-based span-based ...
%approaches~\cite{?} in Natural Language Processing (NLP). They
%successfully learn ... Following suit, we design \tool to learn the
%representations for the statements in source code so as to learn the
%span ...}

\subsubsection{{\bf [Key Idea 3] Leveraging Sequence Chunking with a Language Model and Multi-tasking}} 
Inspired by the sequence chunking
techniques~\cite{sequence-chunking-aaai17} in NLP, we formulate our
problem as identifying one or multiple chunks of consecutive
statements that need to be placed within \code{try-catch} blocks. We
leverage and fine-tune the language model
CodeBERT~\cite{codebert-emnlp20} to learn to the relations among
statements with the API elements.  We also leverage the multi-tasking
framework for all three tasks {\xblock}, {\xstate}, and {\xtype}
because the learning for one task can benefit for another.
%task and vice versa.

%\subsubsection{{\bf [Key Idea 3] Leveraging Explainable AI to predict statements in a try-catch block}} To predict which statements in a given code snippet that need to be placed in a \code{try-catch} block, we leverage the explainable ML
%model, GNNExplainer~\cite{GNNExplainer}, that {\em ``explains'' why
%  the R-GCN model has arrived at its decision}. Specifically, {\tool}
%takes as input the given code, the trained GCN model along with its
%decision on the classification of the task {\xblock} on the given
%code. GNNExplainer will produce the subgraph of the PDG of the given
%code, which is called the {\em explanation subgraph}, that minimizes
%the prediction scores between using the original PDG and using the
%explanation subgraph. That is, that minimal explanation subgraph
%contains the crucial statements that are most decisive to the
%classification result for {\xblock} on the need of a \code{try-catch}
%block.  Thus, those statements returned from GNNExplainer can be
%considered as the statements that need to placed in that block.
