\subsection{Key Ideas}
\label{key:sec}

We design {\tool} for exception handling recommendation for
Java code: given a code snippet, it will 1) predict if a
\code{try-catch} block is required, 2) point out which statements in
the code snippet need to be placed in a \code{try-catch} block, and 3)
suggest what exceptions need to be caught in the \code{catch}
clause. We refer to those three tasks as {\xblock}, {\xstate} and
{\xtype}, respectively. Following Observations 1-5, we design {\tool}
with the following key ideas:



%\vspace{3pt}
\subsubsection{{\bf [Key Idea 1] Neural Network-Based Approach to Exception Handling Recommendation}}
%\vspace{2pt}
%\subsubsection*{{\bf [Key Idea 1] Neural Network-Based Approach to Partial Program Dependence Analysis}}
Instead of deterministically deriving the exceptions to be handled for
a given (incomplete) code snippet, following Observation~\ref{ob2}, we
design a deep learning model (DL) to learn to analyze that snippet to
recommend if a \code{try-catch} block is needed and the statements to
be placed within the \code{try-catch} block, and to recommend the
exception types in the \code{catch} clause.  By learning from the
\code{try-catch} blocks of the complete code in the open-source
projects in the training process, our DL model can help the adaptation
in all three above tasks.

%: 1) deciding what
%statements in the given code snippet to be placed in a
%\code{try-catch} block, and 2) deciding what exceptions to be handled.



\vspace{2pt}
\subsubsection{{\bf [Key Idea 2] Leveraging Context to Avoid
Name Ambiguity and Learning the Relations between API elements and
Exception Types}} Instead of learning only the associations between an
API element and exception types as in XRank~\cite{xrank-fse20},
{\tool} leverages as the context the complete code in the training
corpus, which are parsable and provide the identities (i.e., FQNs) of
the API elements. In predicting for a code snippet, {\tool} will also
leverage the context and dependencies among the API elements to learn
their identities (see Observation~\ref{ob4}). Importantly,
that leads to the learning of the relations between the key API
elements in the context and the handled exception types
(Observation~\ref{ob3}).

%\subsubsection{{\bf [Key Idea 3] Dual-Task Learning between {\xstate} and {\xtype}}} The learning of deciding what statements to be in a \code{try-catch}
%block could benefit much on the learning of deciding what exception
%types to be handled. In Figure~\ref{fig:example4}, if a model learns
%that line 3 (with \code{new\-Buffered\-Reader}) and line 5 (with
%\code{read\-Line}) need to be in \code{try-catch}, it could learn from
%the code corpus and decide \code{IOException} as the exception type to
%be handled. In contrast, if a model learns correctly that the
%\code{IOException} needs to be handled, from the history, it can learn
%that \code{new\-Buffered\-Reader} and \code{read\-Line} can throw that
%exception and determine that the line 3 and 5 need to be in
%\code{try-catch}.

%{\em
%\subsubsection{{\bf [Key Idea 3] Span-based ...}}
%We seek inspiration from the neural network-based span-based ...
%approaches~\cite{?} in Natural Language Processing (NLP). They
%successfully learn ... Following suit, we design \tool to learn the
%representations for the statements in source code so as to learn the
%span ...}


\subsubsection{{\bf [Key Idea 3] Leveraging Explainable AI to Predict Statements in a Try-Catch Block}} To predict which statements in a given code snippet that need to be
placed in a \code{try-catch} block, we leverage the explainable ML
model, GNNExplainer~\cite{GNNExplainer}, that {\em ``explains'' why
  the R-GCN model has arrived at its decision}. Specifically, {\tool}
takes as input the given code, the trained GCN model along with its
decision on the classification of the task {\xblock} on the given
code. GNNExplainer will produce the subgraph of the PDG of the given
code, which is called the {\em explanation subgraph}, that minimizes
the prediction scores between using the original PDG and using the
explanation subgraph. That is, that minimal explanation subgraph
contains the crucial statements that are most decisive to the
classification result for {\xblock} on the need of a \code{try-catch}
block.  Thus, those statements returned from GNNExplainer can be
considered as the statements that need to placed in that
block.
