\subsubsection{RQ4. Dependency Probing}~\\
In this research question, we examine whether {\tool} puts more attention weights for statements inside try blocks. The evaluation is done on the correctly predicted portion of the Github dataset. For each input code snippet, we feed it through the Transformer body of {\tool}, and extract the attention weight matrix from the last layer. We sum up the attention weights between statements inside try blocks, and sum up the attention weights from statements inside to statements outside try blocks (recall that statements are represented by [SEP] tokens). Therefore, for all instances, we have a list of attention scores for inside statements (see Formula~\ref{E:ins}), and a list of attention scores for inside to outside statements (see Formula~\ref{E:out}). Through two sample t\text{-}test, we analyze whether means of the two lists ($\overline{X}_{in}$ and $\overline{Y}_{in\rightarrow out}$) are different and report the p-value. If $p\text{-}value < 0.05$, we reject the Null Hypothesis---there is no difference between the means.

\begin{equation}\label{E:ins}
X_{in} = [ S^{1}_{attn, in}, S^{2}_{attn, in}, ... , S^{n}_{attn, in} ]
\end{equation}

\begin{equation}\label{E:out}
Y_{in\rightarrow out} = [ S^{1}_{attn, in\rightarrow out}, S^{2}_{attn, in\rightarrow out}, ... , S^{n}_{attn, in\rightarrow out} ]
\end{equation}
 
