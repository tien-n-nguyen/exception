\subsection{Comparison on Try-Catch Block Necessity Checking Effectiveness (RQ1)}
\label{sec:rq1}

\begin{table}[htpb]
  \caption{Try-Catch Necessity Checking Comparison (RQ1)}
  \vspace{-12pt}
	\begin{center}
		\renewcommand{\arraystretch}{1}
		\begin{tabular}{p{1.5cm}<{\centering}|p{1.25cm}<{\centering}p{1.25cm}<{\centering}|p{1.25cm}<{\centering}p{1.25cm}<{\centering}}
			\hline
			\multirow{2}{*}{Category} & \multicolumn{2}{c|}{{\tool} Dataset} & \multicolumn{2}{c}{FuzzyCatch Dataset}\\
			\cline{2-5}
			  & \tool  & XRank & \tool  & XRank\\
			\hline
			Recall    & \textbf{0.81} & &&\\
			Precision & \textbf{0.66} & &&\\
			F-score   & \textbf{0.73} & &&\\
			\hline
		\end{tabular}
		\label{tab:xblock}
	\end{center}
\end{table}

%{\color{red}{This section waiting for the XRank Results. But from the current estimate, our approach should have higher F-score. But the recall and precision I'm not sure. Once I have the results, I will update this section.}}

Table~\ref{tab:xblock} displays the comparison result. As seen, our
approach achieves a high level of performance across two datasets. In
{\tool} dataset, with a precision of 66\%, it can decide correctly 2
out of 3 cases whether a code snippet requires a \code{try-catch}
block or not. With a recall of 81\%, {\tool} is able to cover 4 out of
5 cases that needs to be placed in a \code{try-catch} block. Users
just need to find 1 out of 5 cases. As a result, it achieves a high
F-score of 0.73. In FuzzyCatch dataset, {\tool} also achieves a high
level of performance with XX\% precision, YY\% recall, and ZZ\%
F-score.

In comparison, in {\tool} dataset, our model improves relatively over
the state-of-the-art approach, XRank, XX\% in precision, YY\% in
recall, and ZZ\% in F-score. In FuzzyCatch dataset, the relative
improvements are XX\%, YY\%, and ZZ\% in precision, recall, and
F-score, respectively.

We examined closely the cases that {\tool} performed better than
XRank.  First, XRank relies on the association scores between the
presence of API method calls and the presence of a \code{try-catch}
block. The decisions on the necessity of a \code{try-catch} block or
the exception types depend on the pre-defined thresholds in XRank on
those association scores. Thus, those pre-defined thresholds might not
be suitable across all API methods. Second, for the incomplete
code snippets in which the names of the API methods in different
packages or libraries are the same (e.g., \code{toString} or
\code{getText} in various JDK packages), XRank cannot distinguish them
and use one entry in the dictionary for them due to its IR
approach. In contrast, unlike XRank which considers only the API
method calls in a \code{try-catch} block, {\tool} consider the code in
the block as the context to learn the program dependencies among the
names of those API elements. That is, it leverages the relations among
the names of API elements to learn their identities, thus,
deciding better the need of \code{try-catch} blocks and the
corresponding exception types.

For example, in a code snippet, \code{getText} has XXX\% API method
candidates. However, considering that the relation between \code{css}
and \code{getText} in \code{`...()\-.css()\-.getText()'}, we only have
4 candidates for \code{getText}. Finally, considering the return value
of \code{getText} is an argument of \code{setInnerText(...)}, only one
candidate is remained:
\code{com\-.google\-.gwt\-.resources\-.client\-.CssResource\-.getText()}.
Thus, those relations actually can help identify the API elements,
leading to better decision in {\tool} on the \code{try-catch} block
and exception types. Because it has not seen any \code{try-catch}
block involving those API elements, {\tool} decides that the code
snippet does not need a \code{try-catch} block. In contrast, XRank
considers only the {\em pairwise} associate scores between an {\em
  individual API method call} and the presence of a \code{try-catch}
block. It disregards those above relations/dependencies among the API
names. Thus, it might misunderstand that \code{getText} needs a
\code{try-catch} due to the co-occurrences of other API elements that
need one. That is, without the dependency context, XRank might
make incorrect identification of the API elements via their names,
leading to incorrect exception recommendation.
