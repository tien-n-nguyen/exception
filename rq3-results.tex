\subsection{Exception Type Recommendation (RQ3)}
\label{sec:rq3}

\begin{table}[t]
  \caption{Detailed Results on Different Numbers of Exception Types in a
    \code{catch} clause in Oracle Set (RQ3) (Recall)}
  \vspace{-12pt}
	{\small
	  \begin{center}
            \tabcolsep 3.5pt
			\renewcommand{\arraystretch}{1}
			\begin{tabular}{p{4.5cm}<{\centering}|p{1.3cm}<{\centering}|p{1.5cm}<{\centering}}
				\hline
				\# Ex. Types in \code{catch} clause in Oracle Set & Metrics &  Accuracy\\
				\hline
				\multirow{1}{*}{1 (1,385 instances)}   & Hit-1  & 918 (66\%) \\
				\hline
				\multirow{2}{*}{2 (98 instances)}  & Hit-1   & 75 (77\%) \\
				& Hit-2         &  41 (42\%) \\
				\hline
				\multirow{3}{*}{3 (18 instances)}  & Hit-1    & 12 (67\%) \\
				& Hit-2     & 5 (28\%)\\
				& Hit-3     & 3 (17\%) \\
				\hline
				\multirow{4}{*}{3+ (30 instances)}  & Hit-1   & 18 (60\%) \\
				& Hit-2     & 10 (33\%) \\
				& Hit-3     & 4 (13\%)\\
                                \hline
                                & Hit-All$_{Rec}$ & 962 (63\%)\\
				\hline
			\end{tabular}
	                The sum of the percentages in each row section is not 100\% because Hit-1 contains Hit-2, which contains Hit-3, and so on. Hit-$n$: the overlap between the predicted set and the oracle set is at least $n$ exception types.
			\label{tab:recall-3}
		\end{center}
	}
\end{table}

\subsubsection{{\bf Recall on Exception Type Recommendation}}
\label{sec:req3-recall}

Table~\ref{tab:recall-3} displays the {\em Recall} result on how well
{\em {\tool} covers on the actual exception types in the \code{catch}
  clauses in the oracle}. The result is with respect to the instances
(code snippets) in the dataset with different numbers $K$ of exception
types in the \code{catch} clauses: $K$ = the number of exception types
in a \code{catch} clause in the oracle = $1,2,3,3+$. For example, in
the oracle, there are 98 instances with 2 exception types in a
\code{catch} clause. {\tool}'s predicted set correctly contains all 2
exception types for 41 instances (42\%) (\code{Hit-All}$_{Rec}$). The
predicted set contains {\em at least 1 out of 2} exception types for
75 instances (77\%).

%, and contains {\em at least} one exception type for 12 instances (67\%).

%\begin{table}[t]
%	\caption{Results on Recall for Exception Types in a Try-Catch Block in Oracle Set (RQ3)}
%	{\small
%		\begin{center}
%			\renewcommand{\arraystretch}{1}
%			\begin{tabular}{p{1cm}<{\centering}|p{1.5cm}<{\centering}}
%				\hline
%				Metrics & Accuracy \\
%				\hline
%                                Hit-1 & 28,436 (64.7\%)\\
%                                Hit-2 & 1,396\\
%                                Hit-3 & 180\\
%                                Hit-All & 27,037\\
%			\end{tabular}		
%			\label{tab:recall-3-sum}
%		\end{center}
%	}
%\end{table}

%Total: 43,948

%As seen in Table~\ref{tab:recall-3},

There are 1,385 instances (90.5\%) over 1,531 total instances with a
single exception type in the \code{catch} clause in the oracle in the
testing dataset. {\tool} covers correctly the exception type in 918
(66\%) of the instances. There are 98 instances with two exception
types in the oracle and it correctly suggests both types in 41 cases
(42\%).


%In 2,028 instances (77\%), at least one exception type is predicted correctly.

Note that \code{Hit-All}$_{Rec}$ = \code{Hit-$n$} when $n$ (the number
of overlaps between the predicted and oracle sets) = $K$ (the number
of exception types). For $K$=1..3, which is a total of 1,501
instances (98.1\%), {\bf {\tool} covers all the exception types
  (\code{Hit-All}$_{Rec}$) in 962 instances (63\%) in the testing dataset}. That is,
developers do not have to search for other exception types in 63\% of
the cases. Thus, it achieves high \code{Hit-All}$_{Rec}$ in 98.1\% of
  the entire dataset.

%{\color{red}{1. Our model do well on hit-1 condition which means in most cases, our model can at least predict one exception type correctly for a try-catch block. 2. Results show that the more exception types one try-catch block has, our model is harder to predict all of them correctly. }}

\subsubsection{{\bf Precision on Exception Type Recommendation}}
\label{sec:req3-precision}


\begin{table}[t]
  \caption{Detailed Results on Different Numbers of Exception Types in a \code{catch} clause in Predicted Set (RQ3) (Precision)}
	\vspace{-12pt}
	{\small
	  \begin{center}
            \tabcolsep 2pt
			\renewcommand{\arraystretch}{1}
			\begin{tabular}{p{5cm}<{\centering}|p{1.4cm}<{\centering}|p{1.6cm}<{\centering}}
				\hline
				\# Ex. Types in \code{catch} clause in Predicted Set & Metrics & Accuracy \\
				\hline
				\multirow{1}{*}{1 (1,154 instances)}   & Hit-1  & 442 (38\%) \\
				\hline
				\multirow{2}{*}{2 (294 instances)}  & Hit-1   & 90 (31\%) \\
				& Hit-2       						& 61 (21\%) \\
				\hline
				\multirow{3}{*}{3 (83 instances)}  & Hit-1    & 27 (33\%) \\
				& Hit-2         					& 23 (28\%)\\
				& Hit-3         				  	& 6 (7\%) \\
                                \hline
%                                \multirow{4}{*}{3+ (XXX instances)}  & Hit-1   & XXX (XX\%) \\
%				& Hit-2     & XXX (XX\%) \\
%				& Hit-3     & XX (XX\%)\\
%                                \hline
                                & Hit-All$_{Prec}$ & 509 (33\%)\\
				\hline
			\end{tabular}
                        The sum of the percentages in each row section is not 100\% because Hit-1 contains Hit-2, which contains Hit-3, and so on. Hit-$n$: the overlap between the predicted set and the oracle set is at least $n$ exception types.
			\label{tab:precision-3}
		\end{center}
	}
\end{table}

Table~\ref{tab:precision-3} shows the {\em Precision} result, which is
shown with respect to different numbers $K$ of {\em predicted
  exception types} in the \code{catch} clauses. For example, as seen
in Table~\ref{tab:precision-3}, there are a total of 294 instances
(code snippets) in which {\tool} predicted two exception types in a
\code{try-catch} block. Among them, with \code{Hit-1}=31\%, there are
90 instances in which at least one predicted exception type is
correct. With \code{Hit-2}=21\%, there are 61 instances in which both
the predicted exception types are correct (some types might be
missing).
%With \code{Hit-3} = 7\%, there are 6 instances that all three
%predicted exception types are correct (some types might be missing).
Producing the exact-matched sets (\code{Hit-All}) for all exception
types when $K \ge$ 3 is still challenging, however, those cases are
only 1.9\% in the entire~dataset. We do not have the row for 3+
because in our dataset, 98.1\% of the cases have $\leq$3 exception
types, thus, we set 3 as the limit of the number of exception types for {\xtype}.

Importantly, \code{Hit-All}$_{Prec}$ = \code{Hit-$n$} when
$n$ (the number of overlaps between the predicted and oracle sets) =
$k$ (the number of exception types predicted by {\tool}).
For $k$=1..3, which is a total of 1,531 instances (98.1\%), {\bf
  {\tool} predicts correctly all the exception types
  (\code{Hit-All}$_{Prec}$) in 509 instances (33\%)}. That is, in
509 instances (i.e., 33\%), all the predicted exception types are
actually the correct ones. Developers do not have to delete any
exception types in a predicted set, thus, {\tool} can save their efforts.




%For example, when the number of the CC statements in a p redicted set
%is 𝐾 ′=3, there are 23 bugs in which all of those 3 faulty statements
%are correct (there might be other statements missing). There are 27
%bugs in which two of the 3 predicted, faulty statements are
%correct. There are 55 bugs in which only one of the 3 predicted,
%faulty statements are correct. As seen, regardless of 𝑁, FixLocator is
%more precise than the baselines for all 𝐾 ′s.
