\subsection{Exception-Related Bug Detection (RQ5)}
\label{sec:rq1}

\begin{table}[t]%[htpb]
  \caption {Exception-Related Bug Detection (RQ5)}
  \vspace{-12pt}
  \small
	\begin{center}
		\renewcommand{\arraystretch}{1}
		\begin{tabular}{|p{1.75cm}<{\centering}|p{1.75cm}<{\centering}|p{1.75cm}<{\centering}|}
		  \hline
			\multirow{2}{*}{} & \multicolumn{2}{c|}{FuzzyCatch Dataset} \\
			\cline{2-3}
			  & \tool  & FuzzyCatch~\cite{xrank-fse20} \\
			\hline
			Recall    & 0.75 & \textbf{0.76}\\
			Precision & \textbf{0.62} & 0.54\\
			F-score   & \textbf{0.68} & 0.62\\
			\hline
		\end{tabular}
		\label{tab:bug}
	\end{center}
\end{table}

%{\color{red}{This section waiting for the XRank Results. But from the current estimate, our approach should have higher F-score. But the recall and precision I'm not sure. Once I have the results, I will update this section.}}

%Table~\ref{tab:bug} displays the comparison result.

Has seen in Table~\ref{tab:bug}, {\tool} can be used to detect well
real-world exception-related bugs in which a code snippet needs but
did not have a \code{try-catch} block or miss some exceptions. In
comparison, {\tool} improves relatively over
FuzzyCatch~\cite{xrank-fse20} 14.8\% in Precision and
9.8\% in F-score.
%The reason for a higher recall from FuzzyCatch is the same as in
%RQ1. That is,
While the recall values between two models are almost the same,
FuzzyCatch has lower precision. It tends to predict ``Yes'' (buggy)
for all code snippets. That is because if there is an association
score between {\em only} one API method call in the code snippet and
one exception type higher than the threshold, it will decide that the
snippet is buggy. Figure~\ref{fig:example-bug} shows a bug detected by
{\tool}, and its fix (adding a \code{try-catch} block). All buggy code
and fixes are available in FuzzyCatch's repository:
ebrand.ly/ExDataset.

\input{example-bug.tex}


